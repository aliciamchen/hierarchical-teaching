var params = {
    alpha: 4,
    costWeight: 0.05,
    trueTheta: .5, // true coin flip weight
    nTeachers: 2,
	maxExamples: 20,
	teachers: ['A', 'B'],
    teacherExamples: {
		'A': {a: 3, b: 2},
		'B': {a: 3, b: 2}
	},
	learners: [1, 2],
    learnerHypers: {
        1: {a: 2, b: 8},
        2: {a: 8, b: 2}
    },
	inferOptions: { method: 'MCMC', samples: 4000 },
	adaptiveTeacher: 'B'
};

var round = function (num, precision) {
	Number.parseFloat(num.toFixed(precision));
  } ;


// discretizes a beta distribution over hypers (allows dp)
var Beta_disc = cache(function (hypers) {
	return Infer({method: 'enumerate'}, function() {
		var n = uniformDraw(_.range(0, 1, 0.01));
        var bta = Beta({ a: hypers.a == 0 ? 1 : hypers.a, 
                        b: hypers.b == 0 ? 1 : hypers.b});
		factor(bta.score(n));
        return round(n, 2);
	})
});

var L0Mean = cache(function (examples, hypers) {
	var nExamples = examples.a + examples.b + hypers.a + hypers.b;
	return (examples.a + hypers.a) / nExamples;
});

// literal learner
var L0 = cache(function (examples, hypers) {
	return Beta_disc({ a: hypers.a + examples.a, 
		b: hypers.b + examples.b });
});

// pragmatic speaker
var S1 = cache(function (theta, hypers) {
    return Infer({ method: 'enumerate' }, function () {
      var nExamples = uniformDraw(_.range(1, params.maxExamples + 1));
      var alpha = params.alpha, cw = params.costWeight;  
      var nHeads = uniformDraw(_.range(0, nExamples + 1));
      var sampledExamples = {a: nHeads, b: nExamples - nHeads};
      factor(alpha * (L0(sampledExamples, hypers).score(theta) - cw * nExamples));
      return {a: sampledExamples.a, b: sampledExamples.b};
    });
});

// pragmatic learner
var L1 = cache(function (examples, hypers) {
    return Infer({ method: 'enumerate' }, function () {
        var theta = sample(Beta_disc(hypers));
        observe(S1(theta, hypers), examples);
        return theta;
    });
});

// pragmatic learner compares teacher trustworthiness
var L = cache(function (theta, hypers, teacherExamples) {
    return Infer({ method: 'enumerate' }, function () {
        var cw = params.costWeight;
        var teacherClass = uniformDraw(params.teachers);
        var teacher = teacherExamples[teacherClass];
        var nExamples = teacher.a + teacher.b + hypers.a + hypers.b;
//       Q: is this value of cw good enough? how to examine results to check
        factor(params.alpha * (L1(teacher, hypers).score(theta) - cw * nExamples));
        return {teacher: teacherClass};
    });
});


// after speaker sees learner's feedback after step 1, update speaker posterior over class membership
var updateSpeakerPosterior = cache(function (examples, trueLearnerHypers) {
    return Infer(params.inferOptions, function () {
        var learnerClass = uniformDraw(params.learners);
        var learnerHypers = params.learnerHypers[learnerClass];
      
        var learnerDist = L0(examples, learnerHypers);
        var trueLearnerDist = L0(examples, trueLearnerHypers);
        var learnerEstimate = sample(trueLearnerDist);

        observe(learnerDist, learnerEstimate);
      
        return learnerClass;
    })
});


var sequentialModel = cache(function (trueTheta, trueLearnerHypers, teacherExamples) {
    return Infer({ method: 'enumerate' }, function () {
		var step1examples = teacherExamples[params.adaptiveTeacher];
		var step1dist = sample(L(trueTheta, trueLearnerHypers, teacherExamples));
		var speakerPosterior = updateSpeakerPosterior(step1examples, trueLearnerHypers);
		var step2examples = sample(S1(trueTheta, params.learnerHypers[sample(speakerPosterior)]));
		var newTeacherExamples = extend(teacherExamples, {'B': step2examples});
        var step2dist = sample(L(trueTheta, trueLearnerHypers, newTeacherExamples));
        return {
            step1dist: step1dist,
            step2dist: step2dist
        }
    })
});

var posterior = sequentialModel(params.trueTheta, params.learnerHypers[1], params.teacherExamples);


viz.marginals(posterior);
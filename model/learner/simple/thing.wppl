var params = {
    alpha: 4,
    costWeight: 0.01,
    trueThetas: [.7, 0.3], // true coin flip weight
    trueTheta: 0.7,
    nExamples: 10,
    nTeachers: 2,
	maxExamples: 10,
	teachers: ['A', 'B'],
    teacherExamples: {
		'A': {a: 7, b: 3},
		'B': {a: 1, b: 9}
	},
    teacherKnowledgeLevels: ['full', 'partial'],
	learners: [0, 1],
    learnerHypers: [
		{a: 9, b: 1},
        {a: 1, b: 9}
	],
	inferOptions: { method: 'MCMC', samples: 4000 },
	adaptiveTeacher: 'B',
	nonAdaptiveTeacher: 'A'
};

var round = function (num, precision) {
	Number.parseFloat(num.toFixed(precision));
  } ;


// discretizes a beta distribution over hypers (allows dp)
var Beta_disc = cache(function (hypers) {
	return Infer({method: 'enumerate'}, function() {
		var n = uniformDraw(_.range(0, 1, 0.01));
        var bta = Beta({ a: hypers.a == 0 ? 1 : hypers.a, 
                        b: hypers.b == 0 ? 1 : hypers.b});
		factor(bta.score(n));
        return round(n, 2);
	})
});

var L0Mean = cache(function (examples, hypers) {
	var nExamples = examples.a + examples.b + hypers.a + hypers.b;
	return (examples.a + hypers.a) / nExamples;
});

// literal learner
var L0 = cache(function (examplesArray, learnerHypers) {
    var heads = reduce(function (example, acc) { return example.a + acc }, 0, examplesArray);
    var tails = reduce(function (example, acc) { return example.b + acc }, 0, examplesArray);
    return Beta_disc({
        a: _.toNumber(learnerHypers.a + heads),
        b: _.toNumber(learnerHypers.b + tails)
    });
});


// pragmatic speaker
var S1 = cache(function (theta, hypers, nExamples) {
    return Infer({ method: 'enumerate' }, function () {
      var alpha = params.alpha, cw = params.costWeight;  
      var nHeads = uniformDraw(_.range(0, nExamples + 1));
      var sampledExamples = {a: nHeads, b: nExamples - nHeads};
      factor(alpha * (L0([sampledExamples], hypers).score(theta) - cw * nExamples));
      return {a: sampledExamples.a, b: sampledExamples.b};
    });
});

// second example in sequential case
var S_second_ex = cache(function (first_ex, theta, posterior, nExamples) {
    return Infer({ method: 'enumerate' }, function () {
        var learnerClass = sample(posterior);
        var learnerHypers = params.learnerHypers[learnerClass];
        var nHeads = uniformDraw(_.range(0, nExamples + 1));
        var second_ex = { a: nHeads, b: nExamples - nHeads };

        factor(params.alpha * (L0([first_ex, second_ex], learnerHypers).score(theta) 
			- params.costWeight * (first_ex.a + first_ex.b + second_ex.a + second_ex.b)));

        return second_ex;
    })
});

// pragmatic learner
var L1 = cache(function (examplesArray, hypers, nExamples) {
    return Infer({ method: 'enumerate' }, function () {
		var examples = 
		{a: reduce(function (example, acc) { return example.a + acc }, 0, examplesArray),
		b: reduce(function (example, acc) { return example.b + acc }, 0, examplesArray)};
//         print(examples)
        var theta = uniformDraw(params.trueThetas);
        var theta = sample(Beta_disc(hypers));
        observe(S1(theta, hypers, nExamples), examples);
        return theta;
    });
});

// pragmatic learner compares teacher trustworthiness
var L = cache(function (hypers, examples, posterior, nExamples) {
    return Infer({ method: 'enumerate' }, function () {
        var cw = params.costWeight;
		var theta = uniformDraw(params.trueThetas);
        var teacherKnowledge = sample(posterior);
        var assumedHypers = teacherKnowledge == 'full' ? hypers : uniformDraw(params.learnerHypers);
//         judges how much student trusts examples / how close examples are to true theta
        factor(params.alpha * (L1(examples, assumedHypers, nExamples).score(theta) - cw * nExamples));
        return theta;
    });
});


// after speaker sees learner's feedback after step 1, update speaker posterior over class membership
var updateSpeakerPosterior = cache(function (examples, learnerGuess) {
    return Infer({method: 'enumerate'}, function () {
        var learnerClass = uniformDraw(params.learners);
        var learnerHypers = params.learnerHypers[learnerClass];
        
//         observes learner feedback and adjusts posterior as follows
        var learnerDist = L0(examples, learnerHypers);
        observe(learnerDist, learnerGuess);
      
        return learnerClass;
    })
});

// after speaker sees learner's feedback after step 1, update speaker posterior over class membership
var updateLearnerPosterior = cache(function (examplesArray, trueLearnerHypers, nExamples) {
    return Infer({method: 'enumerate'}, function () {
		var examples = 
		{a: reduce(function (example, acc) { return example.a + acc }, 0, examplesArray),
		b: reduce(function (example, acc) { return example.b + acc }, 0, examplesArray)};
        var teacherKnowledge = uniformDraw(params.teacherKnowledgeLevels);
        var teacherAssumedHypers = teacherKnowledge == 'partial' ?  
                                    uniformDraw(params.learnerHypers) : 
                                    trueLearnerHypers;
      
        var theta = uniformDraw(params.trueThetas);
        var teacherDist = S1(theta, teacherAssumedHypers, nExamples);
        var teacherEstimate = sample(teacherDist);
//         print(examples.a)
        observe(teacherDist, examples);
//         condition(teacherEstimate.a == examples.a);
//         print(examples.a)
        return teacherKnowledge;
    })
});

// updateLearnerPosterior([params.teacherExamples['A']], params.learnerHypers[1])


var sequentialModel = cache(function (trueTheta, trueLearnerHypers, teacherExamples) {
    return Infer({ method: 'enumerate' }, function () {
      
        var nExamples = params.nExamples;
//         learner assesses confidence based on teachers' first set of examples
		var step1examples = teacherExamples;
        
		var learnerInitialPosterior = updateLearnerPosterior([step1examples], trueLearnerHypers, nExamples);
//       print(learnerInitialPosterior)
		var step1guess = sample(L(trueLearnerHypers, [step1examples],
                                  learnerInitialPosterior, nExamples));
//         'adaptive' teacher updates posterior on learner hypers
		var speakerPosterior = updateSpeakerPosterior([step1examples], step1guess);
//       print(speakerPosterior)
      
//         considers the learner's new hypers to be the inferred hypers + the first example set
        // var newHypers = sumExamples(params.learnerHypers[sample(speakerPosterior)], step1examples);
      
//         'adaptive' teacher creates a second set of examples based on inferred learner hypers
		var step2examples = sample(S_second_ex(step1examples, trueTheta, 
                                               speakerPosterior, nExamples));
//       print(step2examples)
		var learnerFinalPosterior = updateLearnerPosterior([step1examples, step2examples], 
														trueLearnerHypers, nExamples * 2)
//         print(learnerFinalPosterior)
//         learner reassesses confidence based on combined examples
		// var newTeacherExamples = {'A': sumExamples(teacherExamples[nonAdaptive], teacherExamples[nonAdaptive]), 
        //                           'B': sumExamples(step1examples, step2examples)};
        var step2guess = sample(L(trueLearnerHypers, [step1examples, step2examples],
                                  learnerFinalPosterior, nExamples * 2));
//       print(step2guess)
        return {
            step1guess: step1guess,
            step2guess: step2guess
        }
    })
});

var posterior = sequentialModel(params.trueTheta, params.learnerHypers[1], params.teacherExamples['A']);


viz.marginals(posterior);
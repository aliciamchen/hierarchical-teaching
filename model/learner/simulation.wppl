// webppl simulation.wppl --require webppl-csv --require webppl-json

var params = {
    alpha: 15,
    costWeight: 0,
    trueThetas: [0.01, 0.3, 0.7, 0.99], // true coin flip weight
    nExamples: 5,
    nTeachers: 2,
	teachers: ['A', 'B'],
    teacherKnowledgeLevels: ['full', 'partial'],
	learners: [0, 1],
    learnerHypers: [
		{a: 9, b: 1},
        {a: 1, b: 9}
	],
    guessCost: 0.1
};

var round = function (num, precision) {
	Number.parseFloat(num.toFixed(precision));
  } ;


// discretizes a beta distribution over hypers (allows dp)
var Beta_disc = cache(function (hypers) {
	return Infer({method: 'enumerate'}, function() {
		var n = uniformDraw(_.range(0, 1, 0.01));
        var bta = Beta({ a: hypers.a == 0 ? 1 : hypers.a,
                        b: hypers.b == 0 ? 1 : hypers.b});
		factor(bta.score(n));
        return round(n, 2);
	})
});


var islandPrior = Categorical({vs: params.trueThetas})
var speakerPrior = Categorical({vs: params.learners})

// literal learner
var L0 = cache(function (examplesArray, learnerHypers) {
    return Infer ({ method: 'enumerate' }, function () {
        var theta = sample(islandPrior);
        var heads = reduce(function (example, acc) { return example.a + acc }, 0, examplesArray);
        var tails = reduce(function (example, acc) { return example.b + acc }, 0, examplesArray);
        var learnerDist = Beta({
            a: _.toNumber(learnerHypers.a + heads) == 0 ? 1 : _.toNumber(learnerHypers.a + heads),
            b: _.toNumber(learnerHypers.b + tails) == 0 ? 1 : _.toNumber(learnerHypers.b + tails)
        });

        factor(params.alpha * learnerDist.score(theta));
        return theta;
    })
});


// pragmatic speaker reasons about a learner who decides between the alternatives
var S1 = cache(function (theta, hypers, nExamples) {
    return Infer({ method: 'enumerate' }, function () {
      var nHeads = uniformDraw(_.range(0, nExamples + 1));
      var sampledExamples = {a: nHeads, b: nExamples - nHeads};

      var getUtility = function(theta) {
        var alternatives = filter(function(x) {return x != theta}, params.trueThetas)
        var alternativesScore = reduce(function(x, acc) {return L0([sampledExamples], hypers).score(x) + acc}, 0, alternatives)
        var targetScore = L0([sampledExamples], hypers).score(theta)

        return params.alpha * (targetScore)
      }

      factor(getUtility(theta))

      return {a: sampledExamples.a, b: sampledExamples.b};
    });
});

// uncertain pragmatic speaker
var S = cache(function (theta, nExamples) {
    return Mixture({
        dists: [S1(theta, params.learnerHypers[0], nExamples),
        S1(theta, params.learnerHypers[1], nExamples)],
        ps: [0.5, 0.5]
    })
});

// second example in sequential case
var S_second_ex_partial = cache(function (first_ex, theta, posterior, nExamples) {
    return Infer({ method: 'enumerate' }, function () {
        var learnerClass = sample(posterior);
        var learnerHypers = params.learnerHypers[learnerClass];
        var nHeads = uniformDraw(_.range(0, nExamples + 1));
        var second_ex = { a: nHeads, b: nExamples - nHeads };

        factor(params.alpha * ((1 - params.costWeight) * L0([first_ex, second_ex], learnerHypers).score(theta)
			- params.costWeight * (second_ex.a + second_ex.b)));

        return second_ex;
    })
});

var S_second_ex_full = cache(function (first_ex, theta, hypers, nExamples) {
    return Infer({ method: 'enumerate' }, function () {
        var learnerHypers = hypers;
        var nHeads = uniformDraw(_.range(0, nExamples + 1));
        var second_ex = { a: nHeads, b: nExamples - nHeads };

        factor(params.alpha * ((1 - params.costWeight) * L0([first_ex, second_ex], learnerHypers).score(theta)
			- params.costWeight * (second_ex.a + second_ex.b)));

        return second_ex;
    })
});

var updateSpeakerPosterior = cache(function (examples, guess) {
    return Infer({ method: 'enumerate' }, function () {
        var learnerClass = sample(speakerPrior);
        var learnerHypers = params.learnerHypers[learnerClass];

        var learnerDist = L0(examples, learnerHypers);

        factor(params.alpha * learnerDist.score(guess))
        return learnerClass;
    })
});

// learner reasons about speaker and true hypothesis after seeing the speaker's exampels
var updateLearnerPosterior = cache(function (examplesArray, trueLearnerHypers, nExamples) {
    return Infer({method: 'enumerate'}, function () {
		var examples =
		{a: reduce(function (example, acc) { return example.a + acc }, 0, examplesArray),
		b: reduce(function (example, acc) { return example.b + acc }, 0, examplesArray)};
        var teacherKnowledge = uniformDraw(params.teacherKnowledgeLevels);
        var teacherAssumedHypers = teacherKnowledge == 'partial' ?
                                    uniformDraw(params.learnerHypers) :
                                    trueLearnerHypers;

        var theta = uniformDraw(params.trueThetas);
        var teacherDist = S1(theta, teacherAssumedHypers, nExamples);

        factor(params.alpha * teacherDist.score(examples))
        return {teacherKnowledge: teacherKnowledge,
            theta: theta};
    })
});


var teacherKnowledgeProb = function (teacherExamples, learnerHypers) {
    var score = marginalize(updateLearnerPosterior(teacherExamples, learnerHypers, params.nExamples), 'teacherKnowledge').score('full');
    return round(100 * Math.pow(Math.E, score), 0)
};

var learnerThetaGuess = function (teacherExamples, learnerHypers, concept) {
    var thetaGuessDist = marginalize(updateLearnerPosterior(teacherExamples, learnerHypers, params.nExamples), 'theta')
    var score = thetaGuessDist.score(concept)
    return round(100 * Math.pow(Math.E, score), 0)
};

var sendGuessScore = function (firstExamples, learnerHypers, teacherKnowledgeEstimate) {
    var dist = Infer({method: 'enumerate'}, function () {
        var feedback = uniformDraw(['yes', 'no'])
        var theta = uniformDraw(params.trueThetas)
        var teacherKnowledge = categorical({vs: params.teacherKnowledgeLevels, ps: [teacherKnowledgeEstimate / 100, 1 - (teacherKnowledgeEstimate / 100)]})
        var studentGuess = MAP(L0([firstExamples], learnerHypers)).val
        var speakerPosterior = feedback == 'yes' ? updateSpeakerPosterior([firstExamples], studentGuess) : speakerPrior

        var secondExamples = teacherKnowledge === 'partial' ? sample(S_second_ex_partial(firstExamples, theta, speakerPosterior, 5)) : sample(S_second_ex_full(firstExamples, theta, learnerHypers, 5))

        // console.log(secondExamples)
        var learnerPosteriorTheta = marginalize(updateLearnerPosterior([firstExamples, secondExamples], learnerHypers, 10), 'theta')

        factor(params.alpha * learnerPosteriorTheta.score(theta))
        return feedback
    })

    var score = dist.score('yes')

    return round(100 * Math.pow(Math.E, score), 0)
}

var f = csv.open('../../data/learner/model/v7.csv');
csv.writeLine('block_type,theta,student_a,student_b,first_examples_a,first_examples_b,teacher_knowledge,feedback_choice,first_guess', f);

var trials = _.flattenDeep(
    map(function(theta) {
        return map(function(hypers) {
            return mapN(function(examples_a) {
                    return {
                        theta: theta,
                        hypers: hypers,
                        examples: {
                            a: examples_a,
                            b: params.nExamples - examples_a
                        }
                    }
            }, params.nExamples)
        }, params.learnerHypers)
    }, params.trueThetas)
)


var second_examples = []

map(function (trial) {
	console.log('running');
    var posterior = teacherKnowledgeProb([trial.examples], trial.hypers);
    var islandGuess = learnerThetaGuess([trial.examples], trial.hypers, trial.theta); // TODO: fix this.. why does it change

	csv.writeLine([
		trial.condition,
		trial.theta,
		trial.hypers.a,
		trial.hypers.b,
		trial.examples.a,
		trial.examples.b,
		posterior,
		sendGuessScore(trial.examples, trial.hypers, posterior), // posterior is teacherKnowledgeEstimate; change later
        islandGuess
	].join(','), f);

}, trials);

// console.log(teacherKnowledgeProb([{a: 1, b: 9}], {a: 1, b: 9}))
// console.log(teacherKnowledgeProb([{a: 9, b: 1}], {a: 9, b: 1}))
csv.close(f);

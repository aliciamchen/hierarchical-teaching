// webppl simulation.wppl --require webppl-csv --require webppl-json

var params = {
    alpha: 1,
    costWeight: 0,
    trueThetas: [0.01, 0.3, 0.7, 0.99], // true coin flip weight
    nExamples: 5,
    nTeachers: 2,
	teachers: ['A', 'B'],
    teacherKnowledgeLevels: ['full', 'partial'],
	learners: [0, 1],
    learnerHypers: [
		{a: 9, b: 1},
        {a: 1, b: 9}
	],
    guessCost: 0.1
};

var round = function (num, precision) {
	Number.parseFloat(num.toFixed(precision));
  } ;


// discretizes a beta distribution over hypers (allows dp)
var Beta_disc = cache(function (hypers) {
	return Infer({method: 'enumerate'}, function() {
		var n = uniformDraw(_.range(0, 1, 0.01));
        var bta = Beta({ a: hypers.a == 0 ? 1 : hypers.a,
                        b: hypers.b == 0 ? 1 : hypers.b});
		factor(bta.score(n));
        return round(n, 2);
	})
});

var L0Mean = cache(function (examples, hypers) {
	var nExamples = examples.a + examples.b + hypers.a + hypers.b;
	return (examples.a + hypers.a) / nExamples;
});


var islandPrior = Categorical({vs: params.trueThetas})

// literal learner
var L0 = cache(function (examplesArray, learnerHypers) {
    return Infer ({ method: 'enumerate' }, function () {
        var theta = sample(islandPrior);
        var heads = reduce(function (example, acc) { return example.a + acc }, 0, examplesArray);
        var tails = reduce(function (example, acc) { return example.b + acc }, 0, examplesArray);
        var learnerDist = Beta({
            a: _.toNumber(learnerHypers.a + heads) == 0 ? 1 : _.toNumber(learnerHypers.a + heads),
            b: _.toNumber(learnerHypers.b + tails) == 0 ? 1 : _.toNumber(learnerHypers.b + tails)
        });

        observe(learnerDist, theta);
        return theta;
    })
});


// pragmatic speaker reasons about a learner who decides between the alternatives
var S1 = cache(function (theta, hypers, nExamples) {
    return Infer({ method: 'enumerate' }, function () {
      var nHeads = uniformDraw(_.range(0, nExamples + 1));
      var sampledExamples = {a: nHeads, b: nExamples - nHeads};

      var getUtility = function(theta) {
        var alternatives = filter(function(x) {return x != theta}, params.trueThetas)
        var alternativesScore = reduce(function(x, acc) {return L0([sampledExamples], hypers).score(x) + acc}, 0, alternatives)
        var targetScore = L0([sampledExamples], hypers).score(theta)

        return params.alpha * (targetScore - alternativesScore)
      }

      factor(getUtility(theta))

      return {a: sampledExamples.a, b: sampledExamples.b};
    });
});

// uncertain pragmatic speaker
var S = cache(function (theta, nExamples) {
    return Mixture({
        dists: [S1(theta, params.learnerHypers[0], nExamples),
        S1(theta, params.learnerHypers[1], nExamples)],
        ps: [0.5, 0.5]
    })
});

// learner reasons about speaker and true hypothesis after seeing the speaker's exampels
var updateLearnerPosterior = cache(function (examplesArray, trueLearnerHypers, nExamples) {
    return Infer({method: 'enumerate'}, function () {
		var examples =
		{a: reduce(function (example, acc) { return example.a + acc }, 0, examplesArray),
		b: reduce(function (example, acc) { return example.b + acc }, 0, examplesArray)};
        var teacherKnowledge = uniformDraw(params.teacherKnowledgeLevels);
        var teacherAssumedHypers = teacherKnowledge == 'partial' ?
                                    uniformDraw(params.learnerHypers) :
                                    trueLearnerHypers;

        var theta = uniformDraw(params.trueThetas);
        var teacherDist = S1(theta, teacherAssumedHypers, nExamples);

        observe(teacherDist, examples);
        return {teacherKnowledge: teacherKnowledge,
            theta: theta};
    })
});


var teacherKnowledgeProb = function (teacherExamples, learnerHypers) {
    var score = marginalize(updateLearnerPosterior(teacherExamples, learnerHypers, params.nExamples), 'teacherKnowledge').score('full');
    return round(100 * Math.pow(Math.E, score), 0)
};

var learnerThetaGuess = function (teacherExamples, learnerHypers) {
    var thetaGuessDist = marginalize(updateLearnerPosterior(teacherExamples, learnerHypers, params.nExamples), 'theta')
    var score = thetaGuessDist.score(0.7)
    return round(100 * Math.pow(Math.E, score), 0)
};

var sendGuessScore = function (teacherKnowledgeEstimate) {
    var dist = Infer({method: 'enumerate'}, function () {
        var feedback = uniformDraw(['yes', 'no'])
        var utility =  feedback == 'yes' ? -5 * ((teacherKnowledgeEstimate / 100) + params.guessCost) : -1
        factor(utility)
        return feedback
    })

    var score = dist.score('yes')

    return round(100 * Math.pow(Math.E, score), 0)
}

var f = csv.open('../../data/learner/model/v6.csv');
csv.writeLine('block_type,theta,student_a,student_b,first_examples_a,first_examples_b,teacher_knowledge,feedback_choice,first_guess', f);

var trials = _.flattenDeep(
    map(function(theta) {
        return map(function(hypers) {
            return mapN(function(examples_a) {
                    return {
                        theta: theta,
                        hypers: hypers,
                        examples: {
                            a: examples_a,
                            b: params.nExamples - examples_a
                        }
                    }
            }, params.nExamples)
        }, params.learnerHypers)
    }, params.trueThetas)
)


var second_examples = []

map(function (trial) {
	console.log('running');
    var posterior = teacherKnowledgeProb([trial.examples], trial.hypers);
    var islandGuess = learnerThetaGuess([trial.examples], trial.hypers); // TODO: fix this.. why does it change

	csv.writeLine([
		trial.condition,
		trial.theta,
		trial.hypers.a,
		trial.hypers.b,
		trial.examples.a,
		trial.examples.b,
		posterior,
		sendGuessScore(posterior),
        islandGuess
	].join(','), f);

}, trials);

csv.close(f);

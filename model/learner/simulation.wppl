// webppl simulation.wppl --require webppl-csv --require webppl-json

var params = {
    alpha: 4,
    costWeight: 0.01,
    trueThetas: [.7, 0.3], // true coin flip weight
    trueTheta: 0.7,
    nExamples: 5,
    nTeachers: 2,
	teachers: ['A', 'B'],
    teacherKnowledgeLevels: ['full', 'partial'],
	learners: [0, 1],
    learnerHypers: [
		{a: 9, b: 1},
        {a: 1, b: 9}
	]
};

var round = function (num, precision) {
	Number.parseFloat(num.toFixed(precision));
  } ;


// discretizes a beta distribution over hypers (allows dp)
var Beta_disc = cache(function (hypers) {
	return Infer({method: 'enumerate'}, function() {
		var n = uniformDraw(_.range(0, 1, 0.01));
        var bta = Beta({ a: hypers.a == 0 ? 1 : hypers.a,
                        b: hypers.b == 0 ? 1 : hypers.b});
		factor(bta.score(n));
        return round(n, 2);
	})
});

var L0Mean = cache(function (examples, hypers) {
	var nExamples = examples.a + examples.b + hypers.a + hypers.b;
	return (examples.a + hypers.a) / nExamples;
});

// literal learner

var islandPrior = Categorical({vs: params.trueThetas})


// var L0 = cache(function (examplesArray, learnerHypers) {
//   var heads = reduce(function (example, acc) { return example.a + acc }, 0, examplesArray);
//   var tails = reduce(function (example, acc) { return example.b + acc }, 0, examplesArray);
//   return Beta_disc({
//     a: _.toNumber(learnerHypers.a + heads),
//     b: _.toNumber(learnerHypers.b + tails)
//   });
// });

var L0 = cache(function (examplesArray, learnerHypers) {
    return Infer ({ method: 'enumerate' }, function () {
        var theta = sample(islandPrior);
        var heads = reduce(function (example, acc) { return example.a + acc }, 0, examplesArray);
        var tails = reduce(function (example, acc) { return example.b + acc }, 0, examplesArray);
        var learnerDist = Beta({
            a: _.toNumber(learnerHypers.a + heads) == 0 ? 1 : _.toNumber(learnerHypers.a + heads),
            b: _.toNumber(learnerHypers.b + tails) == 0 ? 1 : _.toNumber(learnerHypers.b + tails)
        });
        
        observe(learnerDist, theta);
        return theta;
    })
});


// pragmatic speaker
var S1 = cache(function (theta, hypers, nExamples) {
    return Infer({ method: 'enumerate' }, function () {
      var alpha = params.alpha, cw = params.costWeight;
      var nHeads = uniformDraw(_.range(0, nExamples + 1));
      var sampledExamples = {a: nHeads, b: nExamples - nHeads};
      factor(alpha * (L0([sampledExamples], hypers).score(theta) - cw * nExamples));
      return {a: sampledExamples.a, b: sampledExamples.b};
    });
});

// uncertain pragmatic speaker
var S = cache(function (theta, nExamples) {
    return Mixture({
        dists: [S1(theta, params.learnerHypers[0], nExamples),
        S1(theta, params.learnerHypers[1], nExamples)],
        ps: [0.5, 0.5]
    })
});

// print(round(expectation(marginalize(S(0.7, 10), 'a')), 0))
// viz.table(S(0.7, 10))
// viz.table(S1(0.7, {a: 9, b: 1}, 10))

// second example in sequential case
var S_second_ex = cache(function (first_ex, theta, posterior, nExamples) {
    return Infer({ method: 'enumerate' }, function () {
        var learnerClass = sample(posterior);
        var learnerHypers = params.learnerHypers[learnerClass];
        var nHeads = uniformDraw(_.range(0, nExamples + 1));
        var second_ex = { a: nHeads, b: nExamples - nHeads };

        factor(params.alpha * (L0([first_ex, second_ex], learnerHypers).score(theta)
			- params.costWeight * (first_ex.a + first_ex.b + second_ex.a + second_ex.b)));

        return second_ex;
    })
});

// pragmatic learner
var L1 = cache(function (examplesArray, hypers, nExamples) {
    return Infer({ method: 'enumerate' }, function () {
		var examples =
		{a: reduce(function (example, acc) { return example.a + acc }, 0, examplesArray),
		b: reduce(function (example, acc) { return example.b + acc }, 0, examplesArray)};
//         print(examples)
        var theta = sample(islandPrior);
        // var theta = sample(Beta_disc(hypers));
        observe(S1(theta, hypers, nExamples), examples);
        return theta;
    });
});

// pragmatic learner compares teacher trustworthiness
var L = cache(function (hypers, examplesArray, nExamples) {
    return Infer({ method: 'enumerate' }, function () {
        var cw = params.costWeight;
		var theta = uniformDraw(params.trueThetas);
        var teacherKnowledge = uniformDraw(params.teacherKnowledgeLevels);
        var examples =
		{a: reduce(function (example, acc) { return example.a + acc }, 0, examplesArray),
		b: reduce(function (example, acc) { return example.b + acc }, 0, examplesArray)};
        var s1Sample = sample(S1(theta, hypers, nExamples));
        var sSample = sample(S(theta, nExamples));
        if(teacherKnowledge == 'full')
        {
//           condition(s1Sample.a == examples.a)
        //   factor(params.alpha * (S1(theta, hypers, nExamples).score(examples)));
        observe(S1(theta, hypers, nExamples), examples)
        }
        else
        {
//           condition(sSample.a == examples.a)
        //   factor(params.alpha * (S(theta, nExamples).score(examples)));
        observe(S(theta, nExamples), examples)
        }
        return {theta: theta, teacherKnowledge: teacherKnowledge};
    });
});


// after speaker sees learner's feedback after step 1, update speaker posterior over class membership
var updateSpeakerPosterior = cache(function (examples, guess) {
    return Infer({ method: 'enumerate' }, function () {
        var learnerClass = uniformDraw(params.learners);
        var learnerHypers = params.learnerHypers[learnerClass];

        // Point estimate
        var learnerEstimate = L0Mean(examples, learnerHypers);
		var guessTheta = guess.a / (guess.a + guess.b);
        var learnerGuessDist = Categorical({
            vs: params.trueThetas,
            ps: [guessTheta, 1 - guessTheta]
          });
        var learnerDist = L0(examples, learnerHypers);
        // Option 1: 'hard' condition on posterior mean (no partial credit)
        //condition(learnerEstimate === trueLearnerEstimate)
        // Option 2: 'soft' condition on posterior mean (credit for being closer)
        // observe(Gaussian({mu: learnerEstimate, sigma: 1}), reportedMean)
        // Option 3: 'soft' condition on reported mean being high-probability under imagined L0
        // (not as 'strong' as if you know the L0 is deterministically reporting posterior mean)
        // observe(L0(data, learnerHypers), reportedMean)
//         condition(learnerEstimate === guessTheta);
		// factor(10 * Gaussian({mu: learnerEstimate, sigma: 1}).score(guessTheta));
        observe(learnerDist, sample(learnerGuessDist))
        return learnerClass;
    })
});

// after speaker sees learner's feedback after step 1, update speaker posterior over class membership
var updateLearnerPosterior = cache(function (examplesArray, trueLearnerHypers, nExamples) {
    return Infer({method: 'enumerate'}, function () {
		var examples =
		{a: reduce(function (example, acc) { return example.a + acc }, 0, examplesArray),
		b: reduce(function (example, acc) { return example.b + acc }, 0, examplesArray)};
        var teacherKnowledge = uniformDraw(params.teacherKnowledgeLevels);
        var teacherAssumedHypers = teacherKnowledge == 'partial' ?
                                    uniformDraw(params.learnerHypers) :
                                    trueLearnerHypers;

        var theta = uniformDraw(params.trueThetas);
        var teacherDist = S1(theta, teacherAssumedHypers, nExamples);

        observe(teacherDist, examples);
        return teacherKnowledge;
    })
});

// updateLearnerPosterior([params.teacherExamples['A']], params.learnerHypers[1])


var sequentialModel = cache(function (trueTheta, trueLearnerHypers, teacherExamples) {
    return Infer({ method: 'enumerate' }, function () {

        var nExamples = params.nExamples;
//         learner assesses confidence based on teachers' first set of examples
		var step1examples = teacherExamples;

        var learnerInitial = sample(L(trueLearnerHypers, [step1examples], nExamples));
		var learnerInitialPosterior = learnerInitial.teacherKnowledge;
//       print(learnerInitialPosterior)
		var step1guess = learnerInitial.theta;
//         'adaptive' teacher updates posterior on learner hypers
		var speakerPosterior = updateSpeakerPosterior([step1examples], step1guess);
//       print(speakerPosterior)

//         considers the learner's new hypers to be the inferred hypers + the first example set
        // var newHypers = sumExamples(params.learnerHypers[sample(speakerPosterior)], step1examples);

//         'adaptive' teacher creates a second set of examples based on inferred learner hypers
		var step2examples = sample(S_second_ex(step1examples, trueTheta,
                                               speakerPosterior, nExamples));
//       print(step2examples)
//         learner reassesses confidence based on combined examples
        var learnerFinal = sample(L(trueLearnerHypers, [step1examples, step2examples], nExamples * 2));
        var step2guess = learnerFinal.theta;

        return {
            step1guess: step1guess,
            learnerInitialPosterior: learnerInitialPosterior,
            step2guess: step2guess,
        }
    })
});


var teacherKnowledgeProb = function (teacherExamples, learnerHypers) {
    var score = updateLearnerPosterior(teacherExamples, learnerHypers, params.nExamples).score('full');
    return round(100 * Math.pow(Math.E, score), 0)
};

var f = csv.open('../../data/learner/model/v2.csv');
csv.writeLine('block_type,theta,student_a,student_b,first_examples_a,first_examples_b,teacher_knowledge,feedback_choice', f);

var trials = json.read('./factors.json');
var second_examples = []

map(function (trial) {
	console.log('running');
    var posterior = teacherKnowledgeProb([trial.examples], trial.hypers);

	csv.writeLine([
		trial.condition,
		trial.theta,
		trial.hypers.a,
		trial.hypers.b,
		trial.examples.a,
		trial.examples.b,
		posterior,
		posterior > 50 ? 'yes' : 'no'
	].join(','), f);

}, trials);

csv.close(f);

var guessesA = _.range(0, 101);
var guesses = map(function (guessA) 
				{ return {a: guessA, b: 100 - guessA} }, 
				guessesA);


var simulate = cache(function (guess, firstExamples, theta, nExamples) 
{   
    var posterior = updateSpeakerPosterior([firstExamples], guess);
    var examplesA = round(expectation(marginalize(S_second_ex(firstExamples, theta, posterior, nExamples), 'a')), 0);
    return {a: examplesA, b: nExamples - examplesA};
});

var output = _.flattenDeep( 
    map ( function (trial) {
      return map ( function (guess) {
          return { 
              theta: trial.theta,
              firstExample: trial.examples,
              guess: guess,
              secondExample: simulate(guess, trial.examples, trial.theta, params.nExamples)
          }
      }, guesses)
    }, trials)
  );

json.write('../../experiments/learner/json/precalc.json', output);
console.log('success! :)');